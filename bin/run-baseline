#!/usr/bin/env python
"""
"""

import argparse
import functools
import itertools
# import operator
import os
from pathlib import Path
import re

import galsim
import joblib
import metadetect
import ngmix
import numpy as np
import pyarrow as pa
import pyarrow.compute as pc
import pyarrow.dataset as ds
import pyarrow.parquet as pq
import yaml

from chromatic_shear_bias import sed_tools, run_utils, lsst

from chromatic_shear_bias.generators import generators, gals, stars


MEDIAN = 0.9543704986572266
# QUANTILES = [0.2306804656982422, 0.9543704986572266, 1.5550565719604492]
# QUANTILES =  [0.10701332092285165, 0.6657802581787111, 1.1894760131835938, 1.700216293334961]
TOL = 0.01


def main():
    args = get_args()

    with open(args.config, "r") as fp:
        config = yaml.safe_load(fp.read())

    simple_gals = gals.simple_gal_generator()

    base_psf = galsim.Gaussian(fwhm=0.9)
    # psf = galsim.ChromaticAtmosphere(
    #     base_psf,
    #     500,
    #     zenith_angle=0 * galsim.degrees,
    #     parallactic_angle=0 * galsim.degrees,
    # )

    rng = np.random.default_rng(args.seed)

    scene_seed = rng.integers(1, 2**64 // 2 - 1)
    # scene_rng = np.random.default_rng(scene_seed)

    # pair_seed = rng.integers(1, 2**64 // 2 - 1)
    # # pair_rng = np.random.default_rng(pair_seed)

    # meas_seed = rng.integers(1, 2**64 // 2 - 1)
    # # meas_rng = np.random.default_rng(meas_seed)

    xsize = 640
    ysize = 640
    psf_size = 53
    pixel_scale = 0.2

    bands = ["r"]
    noises = [
        run_utils.get_sky_rms(
            lsst.exposure_time,
            lsst.zeropoint[band],
            lsst.sky_brightness[band],
            pixel_scale,
        ) / 1e9
        for band in bands
    ]
    print(f"noises: {noises}")
    shear_bands = None
    det_bands = None

    def build_and_measure_pair(scene, star, shear, xsize, ysize, psf_size, pixel_scale, bands, noises, psf, n_coadd, shear_bands, det_bands, config, pair_seed, meas_seed):
        print(f"building and measuring...")
        pair = generators.build_pair(scene, star, shear, psf, bands, noises, xsize, ysize, psf_size, pixel_scale, pair_seed, n_coadd)
        meas = generators.measure_pair(pair, shear_bands, det_bands, config, meas_seed)
        return meas

    jobs = []
    for scene in generators.generate_scenes(args.n_sims, simple_gals, xsize, ysize, pixel_scale, seed=scene_seed, mag=args.mag):
        print(f"Appending job for next scene")
        pair_seed = rng.integers(1, 2**64 // 2 - 1)
        meas_seed = rng.integers(1, 2**64 // 2 - 1)
        jobs.append(
            joblib.delayed(build_and_measure_pair)(scene, galsim.DeltaFunction(), 0.02, xsize, ysize, psf_size, pixel_scale, bands, noises, base_psf, args.n_coadd, shear_bands, det_bands, config, pair_seed, meas_seed)
        )

    print(f"Running jobs in parallel")
    parallel = joblib.Parallel(n_jobs=args.n_jobs, verbose=10)
    results = parallel(jobs)

    # Achromatic measurement pipeline
    # parallel = joblib.Parallel(n_jobs=args.n_jobs, verbose=10)
    # results = parallel(
    #     joblib.delayed(generators.compose(
    #         functools.partial(generators.build_pair, star=galsim.DeltaFunction(), shear=0.02, xsize=xsize, ysize=ysize, psf_size=psf_size, pixel_scale=pixel_scale, bands=bands, noises=noises, psf=base_psf, rng=pair_rng, n_coadd=args.n_coadd),
    #         functools.partial(generators.measure_pair, shear_bands=shear_bands, det_bands=det_bands, config=config, rng=meas_rng)
    #     ))(scene) for scene in generators.generate_scenes(args.n_sims, simple_gals, xsize, ysize, pixel_scale, rng=scene_rng, mag=args.mag)
    # )

    # output file path
    root_path = Path(args.output)
    # if root_path.exists() and not root_path.is_dir():
    #     raise RuntimeError(f"{root_path} exists but is not a directory!")
    if not root_path.exists():
        root_path.mkdir(exist_ok=True)
    # path = root_path / f"{seed}.parquet"

    schema = run_utils._get_schema()
    batches = (pa.RecordBatch.from_pylist(res, schema) for res in results if res)
    # table = pa.Table.from_batches(batches, schema)
    pqwriter = pq.ParquetWriter(
        root_path / f"{args.seed}.parquet",
        schema,
    )
    # pqwriter.write_table(table)
    for batch in batches:
        pqwriter.write_batch(batch)

    # records = []
    # num_rows = 0
    # for res in results:
    #     if res:
    #         records.append(res)
    #         num_rows += len(res)
    #     if num_rows > 1_000_000:
    #         batch = pa.RecordBatch.from_pylist(records, schema)
    #         pqwriter.write_batch(batch)
    #         records = []
    #         num_rows = 0
    # if num_rows > 0:
    #     batch = pa.RecordBatch.from_pylist(records, schema)
    #     pqwriter.write_batch(batch)
    #     records = []
    #     num_rows = 0

    pqwriter.close()


def get_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--config",
        type=str,
        required=True,
        help="Metadetection configuration file [yaml]",
    )
    parser.add_argument(
        "--mag",
        type=float,
        required=False,
        default=None,
        help="r-band magnitude at which to draw galaxies",
    )
    parser.add_argument(
        "--n_coadd",
        type=int,
        required=False,
        default=100,
        help="Number of exposures in coadd [int]",
    )
    parser.add_argument(
        "--seed",
        type=int,
        required=False,
        default=1,
        help="RNG seed [int]",
    )
    parser.add_argument(
        "--n_sims",
        type=int,
        required=False,
        default=1,
        help="Number of sims to run [int]",
    )
    parser.add_argument(
        "--n_jobs",
        type=int,
        required=False,
        default=joblib.cpu_count(),
        # default=max(1, joblib.cpu_count() // 2),
        help="Number of jobs to run [int]",
    )
    parser.add_argument(
        "--output",
        type=str,
        required=False,
        default="",
        help="Output directory"
    )
    return parser.parse_args()


if __name__ == "__main__":
    main()
