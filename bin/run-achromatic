#!/usr/bin/env python
"""
"""

import argparse
from datetime import datetime as dt
import functools
import itertools
import os
from pathlib import Path
import re
import time

import galsim
import joblib
import metadetect
import ngmix
import numpy as np
import pyarrow as pa
import pyarrow.compute as pc
import pyarrow.dataset as ds
import pyarrow.parquet as pq
from tqdm import tqdm, trange
import yaml

from chromatic_shear_bias import sed_tools, run_utils, lsst

from chromatic_shear_bias.generators import gals, stars


def end2end(seed, gal_dict, shear, xsize, ysize, psf_size, pixel_scale, bands, noises, mag, psf, n_coadd, shear_bands, det_bands, config):
    print(f"Making image simulations for scene with seed {seed}")

    rng = np.random.default_rng(seed)

    scene_seed = rng.integers(1, 2**64 // 2 - 1)
    pair_seed = rng.integers(1, 2**64 // 2 - 1)
    meas_seed = rng.integers(1, 2**64 // 2 - 1)

    scene_rng = np.random.default_rng(scene_seed)

    fiducial_star = galsim.DeltaFunction()

    v1 = np.asarray([1, 0], dtype=float)
    v2 = np.asarray([np.cos(np.radians(120)), np.sin(np.radians(120))], dtype=float)
    x_lattice, y_lattice = run_utils.build_lattice(
        xsize,
        ysize,
        10,
        pixel_scale,
        v1,
        v2,
        scene_rng.uniform(0, 360),
        100,
    )  # pixels
    if len(x_lattice) < 1:
        raise ValueError(f"Scene containts no objects!")

    _start_time = time.time()
    gal_indices = scene_rng.choice(gal_dict.get("num_rows"), len(x_lattice))
    gal_params = gal_dict.get("dataset").take(gal_indices, columns=gal_dict.get("columns"), filter=gal_dict.get("predicate")).to_pylist()
    _current_time = time.time()
    _elapsed_time = _current_time - _start_time
    _elapsed_time_formatted = dt.strftime(dt.utcfromtimestamp(_elapsed_time), '%H:%M:%S')
    print(f"loaded galaxies in {_elapsed_time}")

    _start_time = time.time()
    scene_gals = map(gals.build_simple_cosmoDC2_gal, gal_params)

    # persist objects as a list for reiteration
    _scene = [
        gal
        .rotate(scene_rng.uniform(0, 360) * galsim.degrees)
        .shift(x * pixel_scale, y * pixel_scale)
        .shift(
            scene_rng.uniform(-0.5, 0.5) * pixel_scale,
            scene_rng.uniform(-0.5, 0.5) * pixel_scale,
        )
        for (x, y, gal) in zip(x_lattice, y_lattice, scene_gals)
    ]
    _current_time = time.time()
    _elapsed_time = _current_time - _start_time
    _elapsed_time_formatted = dt.strftime(dt.utcfromtimestamp(_elapsed_time), '%H:%M:%S')
    print(f"built galaxies in {_elapsed_time}")

    if mag is not None:
        print(f"Drawing galaxies with r = {mag} mag")
        bp_r = galsim.Bandpass(f"LSST_r.dat", wave_type="nm").withZeropoint("AB")
        scene = [
            obj.withMagnitude(mag, bp_r)
            for obj in _scene
        ]
    else:
        scene = _scene

    res = run_utils.build_and_measure_pair(
        scene,
        fiducial_star,
        shear,
        xsize,
        ysize,
        psf_size,
        pixel_scale,
        bands,
        noises,
        psf,
        n_coadd,
        shear_bands,
        det_bands,
        config,
        pair_seed,
        meas_seed
    )

    return res

def main():
    args = get_args()

    print(f"Using seed {args.seed}")

    with open(args.config, "r") as fp:
        config = yaml.safe_load(fp.read())

    cosmoDC2_predicate = (
        (pc.field("mag_true_r_lsst") < pc.scalar(26))
        & (pc.field("mag_true_i_lsst") < pc.scalar(26))
        & (pc.field("mag_true_z_lsst") < pc.scalar(26))
    )
    cosmoDC2_directory = "/oak/stanford/orgs/kipac/users/smau/cosmoDC2_v1.1.4_parquet"
    cosmoDC2_re_columns = [
        "^galaxy_id$",
        "^redshift_true$",
        "^redshift$",
        "^mag_true_\w_lsst$",
        "^mag_\w_lsst$",
        "^sed_\d+_\d+$",
    ]

    cosmoDC2_dataset = ds.dataset(cosmoDC2_directory, format="parquet")
    cosmoDC2_columns = run_utils.match_expression(cosmoDC2_dataset.schema.names, cosmoDC2_re_columns)
    cosmoDC2_num_rows = cosmoDC2_dataset.count_rows(filter=cosmoDC2_predicate)

    gal_dict = {
        "dataset": cosmoDC2_dataset,
        "columns": cosmoDC2_columns,
        "predicate": cosmoDC2_predicate,
        "num_rows": cosmoDC2_num_rows
    }

    psf = galsim.Gaussian(fwhm=0.9)

    rng = np.random.default_rng(args.seed)

    xsize = 640
    ysize = 640
    psf_size = 53
    pixel_scale = 0.2
    shear = 0.02

    bands = ["g", "r", "i"]
    noises = [
        run_utils.get_sky_rms(
            lsst.exposure_time,
            lsst.zeropoint[band],
            lsst.sky_brightness[band],
            pixel_scale,
        )
        for band in bands
    ]
    shear_bands = [[1]]
    det_bands = [[0, 1, 2]]

    print(f"Configuring jobs")
    jobs = []
    for i in trange(args.n_sims, ncols=80):
        seed = rng.integers(1, 2**64 // 2 - 1)
        jobs.append(
            joblib.delayed(end2end)(
                seed,
                gal_dict,
                shear,
                xsize,
                ysize,
                psf_size,
                pixel_scale,
                bands,
                noises,
                args.mag,
                psf,
                args.n_coadd,
                shear_bands,
                det_bands,
                config
            )
        )

    # with joblib.parallel_config(backend="loky", inner_max_num_threads=2):
    parallel = joblib.Parallel(n_jobs=args.n_jobs, return_as="generator", verbose=10)
    results_generator = parallel(jobs)

    # output file path
    root_path = Path(args.output)
    # if root_path.exists() and not root_path.is_dir():
    #     raise RuntimeError(f"{root_path} exists but is not a directory!")
    if not root_path.exists():
        root_path.mkdir(exist_ok=True)

    print(f"Generating results")
    schema = run_utils._get_schema()
    with pa.OSFile(str(root_path / f"{args.seed}.arrow"), "wb") as sink:
        with pa.ipc.new_file(sink, schema) as writer:
            for results in results_generator:
                if results:
                    print(f"Writing batch")
                    batch = pa.RecordBatch.from_pylist(results, schema)
                    writer.write_batch(batch)
                else:
                    print(f"Skipping empty batch")

    print(f"Finished")


def get_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--config",
        type=str,
        required=True,
        help="Metadetection configuration file [yaml]",
    )
    parser.add_argument(
        "--mag",
        type=float,
        required=False,
        default=None,
        help="r-band magnitude at which to draw galaxies",
    )
    parser.add_argument(
        "--n_coadd",
        type=int,
        required=False,
        default=100,
        help="Number of exposures in coadd [int]",
    )
    parser.add_argument(
        "--seed",
        type=int,
        required=False,
        default=None,
        help="RNG seed [int]",
    )
    parser.add_argument(
        "--n_sims",
        type=int,
        required=False,
        default=1,
        help="Number of sims to run [int]",
    )
    parser.add_argument(
        "--n_jobs",
        type=int,
        required=False,
        default=joblib.cpu_count(),
        # default=max(1, joblib.cpu_count() // 2),
        help="Number of jobs to run [int]",
    )
    parser.add_argument(
        "--output",
        type=str,
        required=False,
        default="",
        help="Output directory"
    )
    return parser.parse_args()


if __name__ == "__main__":
    main()
