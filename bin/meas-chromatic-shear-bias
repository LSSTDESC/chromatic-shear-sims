#!/usr/bin/env python
"""
Staging file for generating simulations and running metadetect
"""

import argparse
import copy
import logging
from pathlib import Path

import yaml
import numpy as np
import pyarrow as pa
import pyarrow.compute as pc
import pyarrow.dataset as ds
import pyarrow.parquet as pq
import tqdm
import joblib

import galsim
import ngmix
import metadetect

from chromatic_shear_bias import run_utils


def compute_shear_pair(batch, shear=0.02):
    # g1p = np.array(data["p.g1"])
    # R11p = (np.array(data["p.g1p"]) - np.array(data["p.g1m"])) / (2 * shear)
    g1p = batch["p.g1"]
    R11p = pc.divide(pc.subtract(batch["p.g1p"], batch["p.g1m"]), 2 * shear)

    # g1m = np.array(data["m.g1"])
    # R11m = (np.array(data["m.g1p"]) - np.array(data["m.g1m"])) / (2 * shear)
    g1m = batch["m.g1"]
    R11m = pc.divide(pc.subtract(batch["m.g1p"], batch["m.g1m"]), 2 * shear)

    # g2p = np.array(data["p.g2"])
    # R22p = (np.array(data["p.g2p"]) - np.array(data["p.g2m"])) / (2 * shear)
    g2p = batch["p.g2"]
    R22p = pc.divide(pc.subtract(batch["p.g2p"], batch["p.g2m"]), 2 * shear)

    # g2m = np.array(data["m.g2"])
    # R22m = (np.array(data["m.g2p"]) - np.array(data["m.g2m"])) / (2 * shear)
    g2m = batch["m.g2"]
    R22m = pc.divide(pc.subtract(batch["m.g2p"], batch["m.g2m"]), 2 * shear)

    # weights = data["weight"]
    # if weights is not None:
    #     w = np.asarray(weights).astype(np.float64)
    # else:
    #     w = np.ones(len(g1p)).astype(np.float64)
    # w /= np.sum(w)

    # if ind is not None:
    #     g1p = g1p[ind]
    #     R11p = R11p[ind]
    #     g1m = g1m[ind]
    #     R11m = R11m[ind]
    #     g2p = g2p[ind]
    #     R22p = R22p[ind]
    #     g2m = g2m[ind]
    #     R22m = R22m[ind]
    #     w = w[ind]

    # msk = (
    #     np.isfinite(g1p) &
    #     np.isfinite(R11p) &
    #     np.isfinite(g1m) &
    #     np.isfinite(R11m) &
    #     np.isfinite(g2p) &
    #     np.isfinite(R22p) &
    #     np.isfinite(g2m) &
    #     np.isfinite(R22m)
    # )
    # g1p = g1p[msk]
    # R11p = R11p[msk]
    # g1m = g1m[msk]
    # R11m = R11m[msk]
    # g2p = g2p[msk]
    # R22p = R22p[msk]
    # g2m = g2m[msk]
    # R22m = R22m[msk]
    # w = w[msk]

    # return (np.nansum(g1p) - np.nansum(g1m)) / (np.nansum(R11p) + np.nansum(R11m))
    # return (
    #     pc.divide(pc.subtract(pc.sum(g1p), pc.sum(g1m)), pc.add(pc.sum(R11p), pc.sum(R11m)))
    # ).as_py() / 0.02 - 1.
    return g1p, g1m, R11p, R11m, g2p, g2m, R22p, R22m


def get_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--config",
        type=str,
        required=True,
        help="Metadetection configuration file [yaml]",
    )
    parser.add_argument(
        "--s2n-cut", type=int, default=10,
    )
    # parser.add_argument(
    #     "--jackknife", type=int, default=None,
    #     help="number of jackknife subsets to use",
    # )
    parser.add_argument(
        "--ormask-cut", type=int, default=None,
        help="Cut to make on ormask. 0 indicates make a cut, 1 indicates no cut.",
    )
    parser.add_argument(
        "--mfrac-cut", type=int, default=None,
        help="Cut to make on mfrac. Given in percentages and comma separated. Cut keeps all objects less than the given value.",
    )
    parser.add_argument("--output", type=str, required=True, help="Output directory")
    parser.add_argument("--method", type=str, required=False, default="bootstrap", help="Method for calculating variance [bootstrap, jackknife]")
    parser.add_argument("--n_resample", type=int, required=False, default=1000, help="Number of resample iterations")
    parser.add_argument(
        "--n_jobs",
        type=int,
        required=False,
        default=joblib.cpu_count(),
        # default=max(1, joblib.cpu_count() // 2),
        help="Number of jobs to run [int]",
    )
    return parser.parse_args()


def get_logger():
    """
    Format logger.
    """
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    ch = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    ch.setFormatter(formatter)
    logger.addHandler(ch)

    return logger


def main():
    """
    Run the simulation and measurement for metadetect noise bias cancellation.
    """
    args = get_args()
    logger = get_logger()

    with open(args.config, "r") as fp:
        config = yaml.safe_load(fp.read())

    # copy the config for safekeeping
    _config = copy.deepcopy(config)

    logger.info(f"Measuring: {vars(args)}")

    logger.info(f"Reading output files")
    dataset = ds.dataset(args.output, format="arrow")

    predicate = \
        pc.field("s2n_cut") == args.s2n_cut
    if args.ormask_cut is not None:
        predicate &= (pc.field("ormask_cut") == args.ormask_cut)
    else:
        predicate &= (pc.field("ormask_cut") == -1)
    if args.mfrac_cut is not None:
        predicate &= (pc.field("mfrac_cut") == args.mfrac_cut)
    else:
        predicate &= (pc.field("mfrac_cut") == -1)

    # # data = dataset.to_table(filter=predicate).to_pydict()
    # # data = dataset.to_table(filter=predicate)
    # data = dataset.filter(predicate)
    # # n_sims_msk = np.sum(data["weight"])
    # # if n_sims_msk <= 0:
    # #     raise RuntimeError("Cuts did not keep any sims!")
    # # else:
    # #     logger.info(f"{n_sims_msk} sims pass cuts")

    logger.info(f"Measuring multiplicative and additive biases")
    m_req = 0.002
    calibration_shear = ngmix.metacal.DEFAULT_STEP
    cosmic_shear = config["shear"]["g"]
    # m_est, m_std, c_est, c_std = run_utils.estimate_biases(
    #     data, calibration_shear, cosmic_shear,
    #     weights=data["weight"],
    #     method=args.method,
    #     n_resample=args.n_resample,
    # )

    seed = 10
    rng = np.random.RandomState(seed=seed)

    jobs = []
    for batch in dataset.to_batches(filter=predicate):
        jobs.append(
            joblib.delayed(compute_shear_pair)(batch, calibration_shear)
        )

    with joblib.Parallel(n_jobs=args.n_jobs, backend="loky", verbose=1) as par:
        vals = par(jobs)

    # val = compute_shear_pair(batch).as_py() / 0.02 - 1
    # vals.append(val)

    vals = np.array(vals)

    def compute_m(arr):
        return (np.mean(arr[:, 0]) - np.mean(arr[:, 1])) / (np.mean(arr[:, 2]) + np.mean(arr[:, 3])) / 0.02 - 1.

    def compute_c(arr):
        return (np.mean(arr[:, 4]) + np.mean(arr[:, 5])) / (np.mean(arr[:, 6]) + np.mean(arr[:, 7]))

    resamples = []
    for i in tqdm.trange(args.n_resample, ncols=80):
        rind = rng.choice(len(vals), size=len(vals), replace=True)
        resamples.append(vals[rind])

    print("m = %0.3e +/- %0.3e [3-sigma]" % (compute_m(vals), np.std(list(map(compute_m, resamples))) * 3))
    print("c = %0.3e +/- %0.3e [3-sigma]" % (compute_c(vals), np.std(list(map(compute_c, resamples))) * 3))

    # logger.info(f"Applying cuts")
    # pmsk = (pdata["s2n_cut"] == args.s2n_cut)
    # if args.ormask_cut is not None:
    #     pmsk &= (pdata["ormask_cut"] == args.ormask_cut)
    # else:
    #     pmsk &= (pdata["ormask_cut"] == -1)
    # if args.mfrac_cut is not None:
    #     pmsk &= (pdata["mfrac_cut"] == args.mfrac_cut)
    # else:
    #     pmsk &= (pdata["mfrac_cut"] == -1)

    # n_sims_msk = np.sum(pdata["weight"][pmsk])
    # if n_sims_msk <= 0:
    #     raise RuntimeError("Cuts did not keep any sims!")
    # else:
    #     logger.info(f"{n_sims_msk} sims pass cuts")

    # logger.info(f"Measuring multiplicative and additive biases")
    # m_req = 0.002
    # calibration_shear = ngmix.metacal.DEFAULT_STEP
    # cosmic_shear = config["shear"]["g"]
    # m_est, m_std, c_est, c_std = run_utils.estimate_biases(
    #     pdata[pmsk], mdata[pmsk], calibration_shear, cosmic_shear,
    #     weights=pdata["weight"][pmsk],
    #     method=args.method,
    #     n_resample=args.n_resample,
    # )

    # print(f"m: {m_est:.3e} +/- {m_std*3:.3e} (3 sigma)")
    # print(f"c: {c_est:.3e} +/- {c_std*3:.3e} (3 sigma)")

    # if np.abs(m_est) < np.abs(m_std * 3):
    #     logger.info(f"unreliable measurement (3-sigma uncertainty > mean measurement)")
    # else:
    #     logger.info(f"reliable measurement (3-sigma uncertainty < mean measurement)")

    # if np.abs(m_est) < 0.002:
    #     logger.info(f"mean multiplicative bias within nominal requirement. ({np.abs(m_est):.3e} < {m_req:.3e})")
    # else:
    #     logger.info(f"mean multiplicative bias exceeds nominal requirement! ({np.abs(m_est):.3e} > {m_req:.3e})")


if __name__ == "__main__":
    main()
