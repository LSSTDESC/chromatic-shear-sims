#!/usr/bin/env python
"""
"""

import argparse
import functools
import itertools
# import operator
import os
from pathlib import Path
import re

import galsim
import joblib
import metadetect
import ngmix
import numpy as np
import pyarrow as pa
import pyarrow.compute as pc
import pyarrow.dataset as ds
import pyarrow.parquet as pq
import yaml

from chromatic_shear_bias import sed_tools, run_utils

from chromatic_shear_bias.generators import generators, gals, stars

def main():
    args = get_args()

    with open(args.config, "r") as fp:
        config = yaml.safe_load(fp.read())

    DC2_predicate = (
        (pc.field("imag") > pc.scalar(19))
        & (pc.field("imag") < pc.scalar(21))
        & pc.match_substring_regex(pc.field("sedFilename"), "^k[mp]*")
    )
    DC2_stars = stars.DC2_generator(predicate=DC2_predicate)

    cosmoDC2_predicate = (
        (pc.field("mag_r_lsst") < pc.scalar(26))
        & (pc.field("mag_i_lsst") < pc.scalar(26))
        & (pc.field("mag_z_lsst") < pc.scalar(26))
    )
    cosmoDC2_gals = gals.cosmoDC2_generator(predicate=cosmoDC2_predicate)

    base_psf = galsim.Gaussian(fwhm=0.9)
    psf = galsim.ChromaticAtmosphere(
        base_psf,
        500,
        zenith_angle=0 * galsim.degrees,
        parallactic_angle=0 * galsim.degrees,
    )

    rng = np.random.default_rng(args.seed)
    scene_seed = rng.integers(1, 2**64 // 2 - 1)
    pair_seed = rng.integers(1, 2**64 // 2 - 1)
    meas_seed = rng.integers(1, 2**64 // 2 - 1)

    seeds = rng.integers(1, 2**64 // 2 - 1, size=args.n_sims)

    xsize = 320
    ysize = 320
    psf_size = 53
    pixel_scale = 0.2

    bands = "gi"

    # # Plotting pipeline
    # pipe = generators.compose(
    #     functools.partial(generators.build_scene, predicate=cosmoDC2_predicate, xsize=xsize, ysize=ysize, pixel_scale=pixel_scale),
    #     functools.partial(generators.build_pair, shear=0.02, predicate=DC2_predicate, xsize=xsize, ysize=ysize, psf_size=psf_size, pixel_scale=pixel_scale, bands=bands, psf=psf, seed=pair_seed),
    #     functools.partial(generators.build_plot, bands=bands)
    # )
    # parallel = joblib.Parallel(n_jobs=args.n_jobs, verbose=100)
    # results = parallel(
    #     joblib.delayed(pipe)(seed) for seed in seeds
    # )

    # for fig in results:
    #     import matplotlib.pyplot as plt
    #     plt.show()
    #     plt.close()

    # Non-color dependent measurement pipeline
    # star = next(DC2_stars)
    # pipe = generators.compose(
    #     functools.partial(generators.build_pair, star=star, shear=0.02, predicate=DC2_predicate, xsize=xsize, ysize=ysize, psf_size=psf_size, pixel_scale=pixel_scale, bands=bands, psf=psf, seed=pair_seed),
    #     functools.partial(generators.measure_pair, config=config, seed=meas_seed),
    # )
    # parallel = joblib.Parallel(n_jobs=args.n_jobs, verbose=100)
    # results = parallel(
    #     joblib.delayed(pipe)(scene) for scene in generators.generate_scenes(args.n_sims, cosmoDC2_gals, xsize, ysize, pixel_scale, scene_seed)
    # )

    # Color dependent measurement pipeline
    star = next(DC2_stars)
    more_stars = [next(DC2_stars), next(DC2_stars)]
    pipe = generators.compose(
        functools.partial(generators.build_pair, star=star, shear=0.02, predicate=DC2_predicate, xsize=xsize, ysize=ysize, psf_size=psf_size, pixel_scale=pixel_scale, bands=bands, psf=psf, seed=pair_seed),
        functools.partial(generators.measure_pair_color, psf=psf, stars=more_stars, psf_size=psf_size, pixel_scale=pixel_scale, bands=bands, config=config, seed=meas_seed),
    )
    parallel = joblib.Parallel(n_jobs=args.n_jobs, verbose=100)
    # Generating scenes is IO bound (many calls to the cosmoDC2 catalog) while
    # the image/obs/measurement pipeline is CPU bound; therefore, we generate
    # the scenes as arguments passed to the pipeline, which joblib parallelizes
    results = parallel(
        joblib.delayed(pipe)(scene) for scene in generators.generate_scenes(args.n_sims, cosmoDC2_gals, xsize, ysize, pixel_scale, scene_seed)
    )

    schema = run_utils._get_schema()
    batches = (pa.RecordBatch.from_pylist(res, schema) for res in results if res)
    table = pa.Table.from_batches(batches, schema)
    pqwriter = pq.ParquetWriter(
        f"{args.seed}.parquet",
        schema,
    )
    pqwriter.write_table(table)


def get_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--config",
        type=str,
        required=True,
        help="Metadetection configuration file [yaml]",
    )
    parser.add_argument(
        "--seed",
        type=int,
        required=False,
        default=1,
        help="RNG seed [int]",
    )
    parser.add_argument(
        "--n_sims",
        type=int,
        required=False,
        default=1,
        help="Number of sims to run [int]",
    )
    parser.add_argument(
        "--n_jobs",
        type=int,
        required=False,
        default=joblib.cpu_count(),
        help="Number of jobs to run [int]",
    )
    return parser.parse_args()


if __name__ == "__main__":
    main()
